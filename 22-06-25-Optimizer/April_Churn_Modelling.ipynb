{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "April Churn-Modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JnDCpetIJ9ok"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Diwakar-Gupta/Data-Science-APRIL/blob/main/22-06-25-Optimizer/April_Churn_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataSet: https://www.kaggle.com/datasets/shrutimechlearn/churn-modelling"
      ],
      "metadata": {
        "id": "2WXACHED3vA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/archive.zip"
      ],
      "metadata": {
        "id": "TQedydp_31Hq",
        "outputId": "8232f237-b7ea-4f31-8ffc-17d0bcaa209d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/archive.zip\n",
            "  inflating: Churn_Modelling.csv     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mnvbj27LUS3X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/Churn_Modelling.csv')"
      ],
      "metadata": {
        "id": "AojrrJCRXtKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "58fJjqAxXyxN",
        "outputId": "d375bfe2-ee6d-490d-b66a-e0060a45e7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
              "0          1    15634602  Hargrave          619    France  Female   42   \n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0       2       0.00              1          1               1   \n",
              "1       1   83807.86              1          0               1   \n",
              "2       8  159660.80              3          1               0   \n",
              "3       1       0.00              2          0               0   \n",
              "4       2  125510.82              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0        101348.88       1  \n",
              "1        112542.58       0  \n",
              "2        113931.57       1  \n",
              "3         93826.63       0  \n",
              "4         79084.10       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb8add1d-898c-4896-a8e7-f1512fe9853a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb8add1d-898c-4896-a8e7-f1512fe9853a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb8add1d-898c-4896-a8e7-f1512fe9853a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb8add1d-898c-4896-a8e7-f1512fe9853a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.drop(columns=['RowNumber', 'CustomerId', 'Surname'])"
      ],
      "metadata": {
        "id": "-7Jcdk4uX0v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "7VMeDZfTYCy6",
        "outputId": "c81049a3-8859-4151-a490-5b4405be4f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
              "0             619    France  Female   42       2       0.00              1   \n",
              "1             608     Spain  Female   41       1   83807.86              1   \n",
              "2             502    France  Female   42       8  159660.80              3   \n",
              "3             699    France  Female   39       1       0.00              2   \n",
              "4             850     Spain  Female   43       2  125510.82              1   \n",
              "...           ...       ...     ...  ...     ...        ...            ...   \n",
              "9995          771    France    Male   39       5       0.00              2   \n",
              "9996          516    France    Male   35      10   57369.61              1   \n",
              "9997          709    France  Female   36       7       0.00              1   \n",
              "9998          772   Germany    Male   42       3   75075.31              2   \n",
              "9999          792    France  Female   28       4  130142.79              1   \n",
              "\n",
              "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
              "0             1               1        101348.88       1  \n",
              "1             0               1        112542.58       0  \n",
              "2             1               0        113931.57       1  \n",
              "3             0               0         93826.63       0  \n",
              "4             1               1         79084.10       0  \n",
              "...         ...             ...              ...     ...  \n",
              "9995          1               0         96270.64       0  \n",
              "9996          1               1        101699.77       0  \n",
              "9997          0               1         42085.58       1  \n",
              "9998          1               0         92888.52       1  \n",
              "9999          1               0         38190.78       0  \n",
              "\n",
              "[10000 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e47f8a2-97eb-4689-a60c-d3569127c401\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e47f8a2-97eb-4689-a60c-d3569127c401')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e47f8a2-97eb-4689-a60c-d3569127c401 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e47f8a2-97eb-4689-a60c-d3569127c401');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=dataset['Exited']"
      ],
      "metadata": {
        "id": "AQ4qhsocYDWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
        "gender=pd.get_dummies(X['Gender'],drop_first=True)"
      ],
      "metadata": {
        "id": "mOK5Y0NUYKeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=pd.concat([X,geography,gender],axis=1)"
      ],
      "metadata": {
        "id": "Crs2ruGHYLIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.drop(['Geography','Gender'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "pl4Bx7TRYa8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "pPMg4gT2Yb6r",
        "outputId": "cd20dc05-5c1c-4c6a-e75e-664a69ac5e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0             619   42       2       0.00              1          1   \n",
              "1             608   41       1   83807.86              1          0   \n",
              "2             502   42       8  159660.80              3          1   \n",
              "3             699   39       1       0.00              2          0   \n",
              "4             850   43       2  125510.82              1          1   \n",
              "...           ...  ...     ...        ...            ...        ...   \n",
              "9995          771   39       5       0.00              2          1   \n",
              "9996          516   35      10   57369.61              1          1   \n",
              "9997          709   36       7       0.00              1          0   \n",
              "9998          772   42       3   75075.31              2          1   \n",
              "9999          792   28       4  130142.79              1          1   \n",
              "\n",
              "      IsActiveMember  EstimatedSalary  Exited  Germany  Spain  Male  \n",
              "0                  1        101348.88       1        0      0     0  \n",
              "1                  1        112542.58       0        0      1     0  \n",
              "2                  0        113931.57       1        0      0     0  \n",
              "3                  0         93826.63       0        0      0     0  \n",
              "4                  1         79084.10       0        0      1     0  \n",
              "...              ...              ...     ...      ...    ...   ...  \n",
              "9995               0         96270.64       0        0      0     1  \n",
              "9996               1        101699.77       0        0      0     1  \n",
              "9997               1         42085.58       1        0      0     0  \n",
              "9998               0         92888.52       1        1      0     1  \n",
              "9999               0         38190.78       0        0      0     0  \n",
              "\n",
              "[10000 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4c2f2e2-f702-4e19-9d92-0104d1b0c2e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>Germany</th>\n",
              "      <th>Spain</th>\n",
              "      <th>Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>771</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>516</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>709</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>772</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>792</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4c2f2e2-f702-4e19-9d92-0104d1b0c2e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4c2f2e2-f702-4e19-9d92-0104d1b0c2e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4c2f2e2-f702-4e19-9d92-0104d1b0c2e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33,random_state=42)"
      ],
      "metadata": {
        "id": "OQnzyDczYlkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "gPJj9GDMY5Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANN MODEL\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "metadata": {
        "id": "wjllextBZBaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "9t_fx6IYb-1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=64, activation='relu',kernel_initializer=initializers.HeUniform()))\n",
        "model.add(Dense(units=8, activation='relu',kernel_initializer=initializers.GlorotUniform()))\n",
        "model.add(Dense(units=1,activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='Nadam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8gF9EZH1Zagg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history=model.fit(X_train,y_train,batch_size=32,epochs=50,validation_split=0.20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh5vsTvRbJZ2",
        "outputId": "2db4f241-0959-4284-de8a-4fc742c38043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "168/168 [==============================] - 2s 3ms/step - loss: 0.1884 - accuracy: 0.9299 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.2158e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 4.8551e-04 - accuracy: 1.0000 - val_loss: 3.9113e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 2.7810e-04 - accuracy: 1.0000 - val_loss: 2.4409e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 1.7941e-04 - accuracy: 1.0000 - val_loss: 1.6689e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 1.2454e-04 - accuracy: 1.0000 - val_loss: 1.2007e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 9.1037e-05 - accuracy: 1.0000 - val_loss: 9.0330e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "168/168 [==============================] - 1s 3ms/step - loss: 6.9015e-05 - accuracy: 1.0000 - val_loss: 6.9987e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 5.3789e-05 - accuracy: 1.0000 - val_loss: 5.5527e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 4.2877e-05 - accuracy: 1.0000 - val_loss: 4.5071e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 3.4779e-05 - accuracy: 1.0000 - val_loss: 3.6975e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 2.8621e-05 - accuracy: 1.0000 - val_loss: 3.0727e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 2.3800e-05 - accuracy: 1.0000 - val_loss: 2.5823e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 2.0022e-05 - accuracy: 1.0000 - val_loss: 2.1911e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 1.6979e-05 - accuracy: 1.0000 - val_loss: 1.8793e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 1.4508e-05 - accuracy: 1.0000 - val_loss: 1.6155e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 1.2462e-05 - accuracy: 1.0000 - val_loss: 1.3969e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 1.0776e-05 - accuracy: 1.0000 - val_loss: 1.2165e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 9.3631e-06 - accuracy: 1.0000 - val_loss: 1.0633e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 8.1703e-06 - accuracy: 1.0000 - val_loss: 9.3384e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 7.1539e-06 - accuracy: 1.0000 - val_loss: 8.2279e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 6.2899e-06 - accuracy: 1.0000 - val_loss: 7.2671e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 5.5437e-06 - accuracy: 1.0000 - val_loss: 6.4402e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 4.9008e-06 - accuracy: 1.0000 - val_loss: 5.7112e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 4.3425e-06 - accuracy: 1.0000 - val_loss: 5.0859e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.8557e-06 - accuracy: 1.0000 - val_loss: 4.5352e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.4299e-06 - accuracy: 1.0000 - val_loss: 4.0513e-06 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.0567e-06 - accuracy: 1.0000 - val_loss: 3.6211e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "168/168 [==============================] - 1s 3ms/step - loss: 2.7284e-06 - accuracy: 1.0000 - val_loss: 3.2391e-06 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 2.4396e-06 - accuracy: 1.0000 - val_loss: 2.9068e-06 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 2.1840e-06 - accuracy: 1.0000 - val_loss: 2.6080e-06 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 1.9568e-06 - accuracy: 1.0000 - val_loss: 2.3429e-06 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 1.7561e-06 - accuracy: 1.0000 - val_loss: 2.1068e-06 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 1.5773e-06 - accuracy: 1.0000 - val_loss: 1.8975e-06 - val_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 1.4187e-06 - accuracy: 1.0000 - val_loss: 1.7117e-06 - val_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 1.2767e-06 - accuracy: 1.0000 - val_loss: 1.5444e-06 - val_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 1.1492e-06 - accuracy: 1.0000 - val_loss: 1.3945e-06 - val_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 1.0358e-06 - accuracy: 1.0000 - val_loss: 1.2589e-06 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 9.3405e-07 - accuracy: 1.0000 - val_loss: 1.1386e-06 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 8.4328e-07 - accuracy: 1.0000 - val_loss: 1.0311e-06 - val_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 7.6139e-07 - accuracy: 1.0000 - val_loss: 9.3241e-07 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 6.8787e-07 - accuracy: 1.0000 - val_loss: 8.4507e-07 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 6.2178e-07 - accuracy: 1.0000 - val_loss: 7.6580e-07 - val_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 5.6257e-07 - accuracy: 1.0000 - val_loss: 6.9531e-07 - val_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 5.0901e-07 - accuracy: 1.0000 - val_loss: 6.3006e-07 - val_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 4.6068e-07 - accuracy: 1.0000 - val_loss: 5.7145e-07 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 4.1733e-07 - accuracy: 1.0000 - val_loss: 5.1828e-07 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.7812e-07 - accuracy: 1.0000 - val_loss: 4.7066e-07 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.4278e-07 - accuracy: 1.0000 - val_loss: 4.2746e-07 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(model_history.history['accuracy'])\n",
        "plt.plot(model_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "p7aHE4emdpEQ",
        "outputId": "0a6acc7f-da46-4a54-f2ec-03a5287da61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_history.history.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5WuI8zLfNxj",
        "outputId": "a1e4bcb7-4395-46b5-fca6-4e751dc01772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "2BCSRK5dfZPO",
        "outputId": "48cca770-c261-420e-f87b-56e02eea7760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)"
      ],
      "metadata": {
        "id": "fGPskDoUfqX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate the Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "score=accuracy_score(y_pred,y_test)\n"
      ],
      "metadata": {
        "id": "0oTH2leqfzeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj6iz_6sf10W",
        "outputId": "282c27d0-a0b9-4489-e535-a20abd48b8ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2657,    0],\n",
              "       [   0,  643]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnYHBRuTf3QL",
        "outputId": "82a1768d-b751-4181-add1-2c1732c550e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model')"
      ],
      "metadata": {
        "id": "3pKx_wClf4uN",
        "outputId": "f48ac2c6-ce46-489b-f661-0173dc316272",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.load_model('model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YldfwJNfgIV3",
        "outputId": "d4c752de-5e18-4749-f067-5d9f5b96e567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f087cc10810>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=tf.keras.models.load_model('model')"
      ],
      "metadata": {
        "id": "aT1_LXD8gUlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers: \n",
        "  print(layer.get_config(), layer.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9ZMZ3NugiNX",
        "outputId": "1aa088b6-854d-45d5-a1e6-d5cfcc5cd129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 32, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} [array([[-0.05777038,  0.29674828, -0.05737912,  0.23211946, -0.19365998,\n",
            "        -0.3219569 , -0.2068489 ,  0.27662683,  0.2884238 ,  0.16190125,\n",
            "        -0.13150668, -0.03947441,  0.3310737 , -0.04211412,  0.03239545,\n",
            "         0.31991616, -0.07770786,  0.03352851,  0.14449604, -0.26211375,\n",
            "        -0.193408  ,  0.12811287, -0.29530555,  0.24816549, -0.17309104,\n",
            "         0.3469185 ,  0.02640148, -0.32972914, -0.27774814, -0.25783566,\n",
            "         0.32531184, -0.02555275],\n",
            "       [-0.13074072,  0.02358635,  0.24900076, -0.03499704, -0.410023  ,\n",
            "         0.251017  , -0.27474844, -0.28813443,  0.18804455,  0.35475904,\n",
            "         0.0541102 , -0.14838593, -0.00411261,  0.3629641 ,  0.21082936,\n",
            "        -0.17732504,  0.22161075, -0.15875489, -0.04837127, -0.11175152,\n",
            "         0.29122663,  0.34121192, -0.0688216 , -0.21293062,  0.13437101,\n",
            "        -0.24712853, -0.24711059, -0.123796  ,  0.04225975, -0.05556936,\n",
            "        -0.02931973, -0.21449193],\n",
            "       [-0.24754404,  0.23309483,  0.06917837,  0.02416425, -0.14748782,\n",
            "         0.18876116,  0.13592751, -0.38066337, -0.32927504, -0.05861888,\n",
            "         0.15536499, -0.0994785 ,  0.17906097, -0.12990518,  0.07559025,\n",
            "         0.22706008,  0.34739643, -0.19313653,  0.33848915,  0.16221488,\n",
            "        -0.09216855, -0.13104126,  0.22210632,  0.22077346, -0.16943395,\n",
            "         0.22477058, -0.06173114, -0.09819829,  0.12243313,  0.16631639,\n",
            "        -0.08850225,  0.16780265],\n",
            "       [ 0.35776615,  0.0284579 , -0.19826236, -0.3307583 , -0.29659092,\n",
            "         0.05536025,  0.09178946, -0.23062648, -0.16190869, -0.19087458,\n",
            "        -0.04008007,  0.22879094, -0.03640378, -0.08255598, -0.11636798,\n",
            "         0.04156294, -0.14709413, -0.02933318, -0.11012698,  0.23666479,\n",
            "        -0.22087108, -0.05380398,  0.36035845, -0.21787725,  0.26294076,\n",
            "        -0.19049437, -0.07017768,  0.40746832, -0.09502387,  0.10714907,\n",
            "        -0.19227323,  0.16992037],\n",
            "       [-0.23264983,  0.24463817, -0.35730898, -0.1853282 ,  0.03938658,\n",
            "         0.01845646, -0.06558725,  0.1078492 , -0.00930953, -0.1201409 ,\n",
            "         0.15360603, -0.38693455,  0.28782275, -0.18607976,  0.23923717,\n",
            "         0.20050515,  0.06501466,  0.3211699 , -0.17235036,  0.03089879,\n",
            "         0.14859654,  0.21889822, -0.15414388,  0.23106046, -0.10700575,\n",
            "        -0.2630383 ,  0.28222594,  0.10160775, -0.14468078,  0.11450744,\n",
            "        -0.30934858,  0.10177028],\n",
            "       [-0.27217093,  0.34144917, -0.08888298, -0.14984217, -0.31113714,\n",
            "        -0.22339615,  0.23585823, -0.15699913,  0.12987004,  0.10391842,\n",
            "        -0.05872256,  0.27720943, -0.19435781, -0.28285462, -0.04379594,\n",
            "         0.3029984 ,  0.22636622, -0.27910712, -0.01924939,  0.31915253,\n",
            "        -0.28312665,  0.11557828,  0.02227213,  0.0533936 ,  0.12266636,\n",
            "        -0.25927764, -0.12471586,  0.09448029,  0.14878683,  0.35457578,\n",
            "         0.2756552 , -0.18781385],\n",
            "       [ 0.21829258, -0.2415565 , -0.20213334,  0.0597408 ,  0.01748748,\n",
            "        -0.03487404, -0.2517689 , -0.174526  ,  0.23683214, -0.11597813,\n",
            "        -0.19665205,  0.24915294,  0.10895297,  0.34362   , -0.13712472,\n",
            "         0.03970472,  0.02871882,  0.29022947, -0.14678015, -0.23260191,\n",
            "        -0.03627339,  0.31220973,  0.23387915, -0.06717812, -0.14091238,\n",
            "        -0.3187002 , -0.20749721, -0.20152597,  0.15441501,  0.04561774,\n",
            "         0.01253109,  0.22102295],\n",
            "       [-0.06622867,  0.12379467,  0.2572689 ,  0.2904169 ,  0.09956152,\n",
            "        -0.14696522,  0.38215244,  0.06975512, -0.04773094, -0.35171464,\n",
            "         0.13414133,  0.36047554,  0.10410814,  0.19175701, -0.17446806,\n",
            "        -0.3415254 , -0.2471977 ,  0.20213062,  0.24402168,  0.21578027,\n",
            "        -0.14973348, -0.04136303,  0.26975673,  0.03562497,  0.04944686,\n",
            "        -0.19079825, -0.15180096,  0.0532969 ,  0.2993579 ,  0.01609771,\n",
            "        -0.1949438 , -0.21520159],\n",
            "       [-0.29232696, -0.47868755,  0.561357  , -0.04496255, -0.3693305 ,\n",
            "        -0.52886724, -0.4095869 , -0.01689834, -0.47996226,  0.33718765,\n",
            "         0.20226182,  0.06529371,  0.28245682,  0.01792098,  0.3104498 ,\n",
            "        -0.45551977, -0.11289091,  0.35507238, -0.31538427, -0.26062027,\n",
            "        -0.09320386, -0.5267048 , -0.2612573 ,  0.2961567 ,  0.20085663,\n",
            "        -0.36628422, -0.33877462,  0.14396504,  0.2646554 , -0.10555737,\n",
            "        -0.3829324 ,  0.55578405],\n",
            "       [ 0.34680274,  0.32467714, -0.09347603,  0.18988739, -0.3039921 ,\n",
            "        -0.27927285,  0.15350392, -0.13129152,  0.24862896,  0.09877698,\n",
            "         0.25911468, -0.00895785, -0.12204012,  0.31123865,  0.14250694,\n",
            "         0.14474024, -0.02117997,  0.22071958, -0.05264245,  0.27509984,\n",
            "        -0.39081487, -0.4389127 ,  0.15094465,  0.2938899 , -0.39496452,\n",
            "         0.07074945, -0.10976195,  0.31868443, -0.01233029,  0.08727048,\n",
            "        -0.20388432, -0.19216248],\n",
            "       [ 0.16542892,  0.29902244,  0.2161555 , -0.22661811, -0.12631187,\n",
            "         0.0441141 , -0.08198173, -0.24026072,  0.21489784, -0.21944389,\n",
            "        -0.21102889, -0.06929291,  0.3619742 , -0.3780138 , -0.1464899 ,\n",
            "        -0.23410806, -0.31944618,  0.10052264, -0.07345018,  0.20832925,\n",
            "        -0.35357717, -0.00443338,  0.14503236, -0.39235485,  0.00198227,\n",
            "         0.30268353,  0.01546748,  0.24855632, -0.19593488, -0.21949866,\n",
            "        -0.16860545, -0.27096954],\n",
            "       [-0.21012951,  0.30442184, -0.20001058,  0.35369566,  0.12702863,\n",
            "         0.10354294, -0.20500451, -0.11151009, -0.30312753, -0.25918508,\n",
            "        -0.17980377, -0.1765403 ,  0.14904499, -0.30042604,  0.21140513,\n",
            "         0.34582567,  0.26135322,  0.09127004, -0.39295357, -0.16039978,\n",
            "        -0.43408954,  0.22205646,  0.23286629,  0.13106655,  0.40094337,\n",
            "        -0.06430042,  0.12564327, -0.03987286,  0.14682023,  0.26755655,\n",
            "         0.16953231,  0.15427458]], dtype=float32), array([ 0.12322752,  0.19200295,  0.16388   ,  0.00551016,  0.1436085 ,\n",
            "        0.18777154,  0.01353217,  0.0801728 ,  0.17009406,  0.07813215,\n",
            "        0.05806457,  0.0866693 ,  0.01752635,  0.03806638, -0.02711665,\n",
            "        0.17018174, -0.00850542,  0.09129381,  0.1526299 ,  0.09979357,\n",
            "        0.14229436,  0.18254462,  0.11808879,  0.0820307 ,  0.11129589,\n",
            "        0.04363786,  0.17599653,  0.02642718, -0.00177771,  0.07910696,\n",
            "        0.22751772,  0.11847365], dtype=float32)]\n",
            "{'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 64, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'HeUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} [array([[-0.43420225, -0.3563283 ,  0.3753354 , ..., -0.23501664,\n",
            "         0.4479345 , -0.17500772],\n",
            "       [ 0.27735138,  0.44652516,  0.43396765, ..., -0.47548944,\n",
            "        -0.21522667,  0.28737232],\n",
            "       [ 0.03153917,  0.15466972, -0.41634992, ...,  0.4506079 ,\n",
            "         0.26323327,  0.5254591 ],\n",
            "       ...,\n",
            "       [ 0.04797176,  0.33891764,  0.40369698, ...,  0.053394  ,\n",
            "         0.07322418, -0.12187774],\n",
            "       [-0.04448706,  0.32215098,  0.06670158, ...,  0.06703129,\n",
            "         0.00310802,  0.34406045],\n",
            "       [-0.39764765,  0.12312151,  0.309407  , ...,  0.15406397,\n",
            "        -0.34857962,  0.6038056 ]], dtype=float32), array([-0.04586364, -0.04146348,  0.06386256,  0.07234713,  0.14785047,\n",
            "        0.1527663 ,  0.07032602,  0.08733681,  0.03485826,  0.13149107,\n",
            "        0.04263467,  0.05101898,  0.12901996,  0.07521782, -0.04147976,\n",
            "        0.15937042,  0.1040111 , -0.04563643,  0.11813557,  0.00458123,\n",
            "        0.02285679,  0.01808017,  0.11747797,  0.17223436,  0.04728067,\n",
            "        0.07812256, -0.03945267,  0.08127179,  0.0510565 ,  0.03919397,\n",
            "        0.09604214, -0.02660863, -0.02528727,  0.11370762,  0.07637008,\n",
            "        0.07593884,  0.10064913,  0.03468078, -0.05042486,  0.07367054,\n",
            "        0.10176795, -0.02853301, -0.01755708,  0.08491398, -0.00293009,\n",
            "        0.11407325,  0.08199025,  0.09048901, -0.03546334, -0.04525321,\n",
            "        0.1916623 , -0.05146701,  0.14806351,  0.17838576,  0.12192103,\n",
            "        0.07213593, -0.06045904, -0.04497755,  0.09059513, -0.00902928,\n",
            "        0.08937038,  0.05918561,  0.08214965,  0.06604482], dtype=float32)]\n",
            "{'name': 'dense_18', 'trainable': True, 'dtype': 'float32', 'units': 8, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} [array([[ 0.02695958, -0.06972895, -0.22178712, -0.09555783,  0.21127881,\n",
            "        -0.08960041, -0.2182795 , -0.21487488],\n",
            "       [-0.08765462,  0.16449775,  0.12307375, -0.10897138, -0.1711275 ,\n",
            "         0.09731592, -0.15663177, -0.22926661],\n",
            "       [-0.22358753,  0.01502332,  0.18678676,  0.2768829 ,  0.12779483,\n",
            "         0.3022548 , -0.09748551,  0.27568105],\n",
            "       [-0.17950873,  0.21836749,  0.2788992 ,  0.02148003, -0.28636703,\n",
            "         0.36551145,  0.14689575, -0.01913378],\n",
            "       [ 0.10717181,  0.30427486,  0.13009894, -0.24488221,  0.11154309,\n",
            "        -0.05362183,  0.35540795, -0.11504667],\n",
            "       [-0.21268272,  0.03279636,  0.08191621,  0.48531455,  0.01905691,\n",
            "         0.13803312, -0.11431982,  0.30575666],\n",
            "       [ 0.24085326,  0.03167273,  0.18294793, -0.01362979,  0.09562387,\n",
            "         0.23444538, -0.2404874 ,  0.14743556],\n",
            "       [-0.25420943, -0.22031534,  0.3327529 ,  0.22603145, -0.20014636,\n",
            "        -0.02611919, -0.256357  ,  0.08296774],\n",
            "       [ 0.25923064,  0.2829746 ,  0.1439357 , -0.09568678, -0.04410613,\n",
            "        -0.25227377,  0.15278052, -0.157867  ],\n",
            "       [-0.29266378, -0.0157114 ,  0.3305868 ,  0.4604843 ,  0.15992558,\n",
            "         0.23320214, -0.19700669,  0.22045523],\n",
            "       [ 0.3912576 ,  0.12802513, -0.15224934,  0.04202938,  0.09337609,\n",
            "        -0.23328425,  0.32554296, -0.34158483],\n",
            "       [-0.03052725, -0.20180976,  0.11793935,  0.18382493, -0.13090493,\n",
            "         0.00258471,  0.08706465,  0.21397375],\n",
            "       [-0.1957919 ,  0.07105443,  0.12862162,  0.17412601, -0.26616034,\n",
            "         0.10273723, -0.01221864,  0.04579921],\n",
            "       [-0.2646129 , -0.08380681,  0.1645492 ,  0.46025026, -0.14400524,\n",
            "         0.14244539, -0.26389885,  0.20397565],\n",
            "       [-0.03443323,  0.07084157, -0.21004072,  0.00894663,  0.11100395,\n",
            "         0.13873215,  0.21014474, -0.16912203],\n",
            "       [ 0.08243489,  0.14754757,  0.05519202,  0.49150977,  0.04074787,\n",
            "         0.19064663,  0.23975389,  0.35194033],\n",
            "       [ 0.19161627,  0.3351603 ,  0.24430954,  0.2567361 , -0.1929993 ,\n",
            "        -0.02429165, -0.08581472,  0.31501952],\n",
            "       [-0.0433947 , -0.1501474 , -0.13318068,  0.00880262, -0.0674883 ,\n",
            "        -0.12619737, -0.1869244 ,  0.22769776],\n",
            "       [ 0.08000443, -0.22687878,  0.35866433,  0.47709227, -0.02509008,\n",
            "         0.39708287, -0.31490186,  0.33276996],\n",
            "       [ 0.18069382,  0.2559527 , -0.19381475, -0.02754923, -0.23485216,\n",
            "         0.14239746, -0.21334602,  0.12348681],\n",
            "       [-0.24414548,  0.27734825,  0.25804862,  0.20287041, -0.12169097,\n",
            "         0.19901028, -0.00136799,  0.00608878],\n",
            "       [ 0.36159036,  0.20500256, -0.20585912,  0.03878625, -0.1553064 ,\n",
            "        -0.0356561 ,  0.29294258, -0.13697945],\n",
            "       [ 0.41422063,  0.11127299, -0.08998687,  0.06432527,  0.4015284 ,\n",
            "         0.07124776,  0.21203874, -0.24178332],\n",
            "       [ 0.20876005, -0.21093254,  0.24819581,  0.2181473 ,  0.18287769,\n",
            "         0.3129322 ,  0.14446868,  0.38378263],\n",
            "       [ 0.14706762,  0.12104286, -0.22390184, -0.13201088, -0.00766451,\n",
            "         0.11908785,  0.19779831,  0.28754386],\n",
            "       [-0.03872082,  0.14912722,  0.08375975, -0.19097643, -0.12230162,\n",
            "         0.19389866,  0.33053878,  0.10349576],\n",
            "       [ 0.23837231, -0.12273746, -0.24553975,  0.01063262, -0.06402815,\n",
            "        -0.11234797,  0.09754796, -0.0570398 ],\n",
            "       [-0.0188866 ,  0.06086741,  0.38829222, -0.04044785, -0.1802109 ,\n",
            "         0.31054714, -0.24289359,  0.1089968 ],\n",
            "       [ 0.17800291, -0.04763727, -0.31139594,  0.15225013,  0.2920988 ,\n",
            "        -0.11037019,  0.29623076, -0.3014434 ],\n",
            "       [ 0.12655888,  0.32198164,  0.15168208,  0.1667037 ,  0.23258509,\n",
            "        -0.05048194,  0.3293872 , -0.16441865],\n",
            "       [ 0.22205304,  0.3299965 , -0.12551461,  0.05595392, -0.01620896,\n",
            "        -0.03320967,  0.02032422,  0.09891987],\n",
            "       [-0.14835614, -0.1788338 , -0.22080438,  0.11929797,  0.00160337,\n",
            "         0.21735947,  0.27053806,  0.12444969],\n",
            "       [ 0.07685954, -0.06449474, -0.13358296, -0.2401706 ,  0.2633115 ,\n",
            "        -0.31619668,  0.39780974,  0.040926  ],\n",
            "       [-0.3170432 , -0.22662404,  0.25913885,  0.37147847,  0.15456654,\n",
            "         0.1554309 , -0.19740477,  0.37345344],\n",
            "       [ 0.22743756,  0.24383116, -0.31085816, -0.3682374 ,  0.34835282,\n",
            "        -0.08927319,  0.01504691, -0.28169417],\n",
            "       [ 0.2722422 , -0.20360167,  0.26917398,  0.3403529 , -0.05571442,\n",
            "         0.27780885, -0.21535608,  0.17033239],\n",
            "       [-0.18887582,  0.22147357,  0.26186913,  0.03985432,  0.06274255,\n",
            "         0.13460864,  0.3071554 , -0.16448359],\n",
            "       [ 0.10766245, -0.0316861 ,  0.12949616,  0.00886145, -0.02646767,\n",
            "        -0.19279647, -0.08825724,  0.1663681 ],\n",
            "       [-0.0105305 , -0.0396525 , -0.22638631, -0.07695646,  0.19146423,\n",
            "         0.29209873, -0.08439324, -0.13913545],\n",
            "       [-0.19202223, -0.20981008,  0.20273013,  0.06159317, -0.20921516,\n",
            "         0.01509413, -0.01056182,  0.02776245],\n",
            "       [-0.28601682, -0.33044732,  0.3350396 ,  0.32227135,  0.1498736 ,\n",
            "         0.21219437, -0.02333142,  0.00699852],\n",
            "       [ 0.22223327,  0.21710926, -0.02808218, -0.07004667,  0.216253  ,\n",
            "        -0.07806882, -0.17547031, -0.24868305],\n",
            "       [ 0.345732  ,  0.23282406, -0.12840608,  0.20485428,  0.12626974,\n",
            "        -0.19133666,  0.19285887, -0.06078752],\n",
            "       [-0.09777343,  0.229862  ,  0.01204547,  0.47014216, -0.26099893,\n",
            "         0.34128922, -0.1812091 ,  0.06295869],\n",
            "       [-0.02930921,  0.2466713 ,  0.1714244 , -0.05306529,  0.15011093,\n",
            "         0.05511618,  0.1642882 , -0.25794438],\n",
            "       [ 0.3375783 ,  0.10602081, -0.2849427 , -0.34902957, -0.11144751,\n",
            "        -0.09208965,  0.37609065, -0.22141612],\n",
            "       [-0.3140633 ,  0.05690907,  0.1525277 ,  0.39132878, -0.29978332,\n",
            "        -0.02165454, -0.03844703,  0.24326243],\n",
            "       [-0.06944858,  0.05337033,  0.0437709 ,  0.22402918, -0.10876986,\n",
            "         0.13584356, -0.04471779,  0.24201614],\n",
            "       [-0.10104837,  0.29327762, -0.23838162,  0.3102373 ,  0.2531251 ,\n",
            "        -0.16554037, -0.04056257,  0.06005539],\n",
            "       [ 0.22126159, -0.21275954, -0.22633347,  0.03886905,  0.03831504,\n",
            "         0.16400474,  0.07250471,  0.12294653],\n",
            "       [ 0.1514136 , -0.3829208 ,  0.22682378,  0.54145736, -0.24555477,\n",
            "         0.31590548, -0.03040441, -0.08286911],\n",
            "       [ 0.30379504, -0.19347385, -0.1542995 ,  0.01524309,  0.21975902,\n",
            "         0.28269753, -0.16159461,  0.21147707],\n",
            "       [-0.02604883,  0.19517569,  0.1787931 ,  0.30765802,  0.10179658,\n",
            "         0.03895234,  0.18660742,  0.3419434 ],\n",
            "       [ 0.14302306, -0.12906349,  0.0500152 ,  0.40458214, -0.13445081,\n",
            "         0.3914431 , -0.14239646,  0.29077047],\n",
            "       [ 0.05450072,  0.06295957,  0.32672194,  0.15536581,  0.15476465,\n",
            "         0.04351326,  0.01298757,  0.05177449],\n",
            "       [ 0.18959394,  0.13948664,  0.22441398, -0.19260463, -0.13684413,\n",
            "         0.2705062 ,  0.21408665,  0.0664883 ],\n",
            "       [-0.03245482,  0.13040337, -0.21606533,  0.02330513,  0.07838949,\n",
            "        -0.01141338, -0.19372039, -0.09045025],\n",
            "       [ 0.23646206, -0.17588651,  0.10189773, -0.21621194,  0.05676207,\n",
            "         0.01041047, -0.02889328, -0.16890222],\n",
            "       [ 0.04117522,  0.395369  , -0.26606625, -0.33780602,  0.32648334,\n",
            "        -0.3514287 ,  0.09091747, -0.01658054],\n",
            "       [-0.22698203, -0.21620962, -0.04254438,  0.32148507, -0.29975304,\n",
            "         0.2648908 , -0.18792064,  0.16380297],\n",
            "       [ 0.12260648,  0.18553974,  0.30798835,  0.10211316,  0.21496879,\n",
            "        -0.08233205, -0.12167627,  0.18953635],\n",
            "       [ 0.31645676, -0.03579533, -0.0239412 , -0.12138893,  0.22473149,\n",
            "         0.19842508,  0.378792  , -0.18775393],\n",
            "       [ 0.0927067 , -0.03962862,  0.3257303 ,  0.1628017 , -0.32502005,\n",
            "         0.19053355,  0.22376095, -0.11690511],\n",
            "       [-0.00982415,  0.36719042, -0.22775921, -0.36580816, -0.02989195,\n",
            "        -0.17586033,  0.14831099, -0.13374108]], dtype=float32), array([ 0.03222922,  0.08109389,  0.07186028,  0.15633915, -0.03177581,\n",
            "        0.05459637,  0.04896038,  0.05268065], dtype=float32)]\n",
            "{'name': 'dense_19', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} [array([[ 0.3750572 ],\n",
            "       [ 1.2225758 ],\n",
            "       [-0.6735017 ],\n",
            "       [-0.33901423],\n",
            "       [ 0.43230006],\n",
            "       [-0.38424686],\n",
            "       [ 0.90325147],\n",
            "       [-0.5049232 ]], dtype=float32), array([-0.04476047], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOktskrClc-Z",
        "outputId": "115e6094-4842-48a3-b893-69d8757e3a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 15.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.6.15)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.1.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.46.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.7)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.2 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter"
      ],
      "metadata": {
        "id": "JnDCpetIJ9ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[12]):\n",
        "    model = keras.models.Sequential()\n",
        "    options = {\"input_shape\": input_shape}\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
        "        options = {}\n",
        "    model.add(keras.layers.Dense(1, **options))\n",
        "    optimizer = keras.optimizers.SGD(learning_rate)\n",
        "    model.compile(optimizer='Nadam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "Iy7odfB-n0Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
      ],
      "metadata": {
        "id": "lSgAKF0OKQC_",
        "outputId": "6c3a152e-25f4-47fe-a134-1d16540b2a70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras_reg.fit(X_train, y_train, epochs=100,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=4)])\n",
        "mse_test = keras_reg.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "58p5DiKYKU42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_distribs = {\n",
        "    \"n_hidden\": [0, 1, 2, 3],\n",
        "    \"n_neurons\": np.arange(1, 100),\n",
        "    \"learning_rate\": [1e-3, 1e-5, 1e-7],\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
        "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
        "                  validation_data=(X_test, y_test),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=3)])"
      ],
      "metadata": {
        "id": "RRP3gnaZKmVT",
        "outputId": "c93008f1-b600-4af5-9e88-8062487e3a03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "140/140 [==============================] - 3s 7ms/step - loss: 0.3125 - accuracy: 0.9158 - val_loss: 0.0977 - val_accuracy: 0.9727\n",
            "Epoch 2/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9845 - val_loss: 0.0317 - val_accuracy: 0.9909\n",
            "Epoch 3/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.0136 - val_accuracy: 0.9958\n",
            "Epoch 4/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.0066 - val_accuracy: 0.9976\n",
            "Epoch 5/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
            "Epoch 6/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0023 - val_accuracy: 0.9997\n",
            "Epoch 7/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0015 - val_accuracy: 0.9997\n",
            "Epoch 8/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 9.8226e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.6752e-04 - accuracy: 1.0000 - val_loss: 7.8342e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 3.2179e-04 - accuracy: 1.0000 - val_loss: 6.2173e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.9137e-04 - accuracy: 1.0000 - val_loss: 4.9902e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.1472e-04 - accuracy: 1.0000 - val_loss: 4.2936e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 7.3081e-05 - accuracy: 1.0000 - val_loss: 3.7409e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.0173e-05 - accuracy: 1.0000 - val_loss: 3.4564e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 3.1295e-05 - accuracy: 1.0000 - val_loss: 2.9408e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.2214e-06 - accuracy: 1.0000 - val_loss: 2.7838e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.7840e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.7840e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.7840e-04 - val_accuracy: 1.0000\n",
            "70/70 [==============================] - 0s 1ms/step - loss: 2.9140e-04 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "140/140 [==============================] - 2s 4ms/step - loss: 0.9961 - accuracy: 0.8216 - val_loss: 0.2789 - val_accuracy: 0.8809\n",
            "Epoch 2/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9190 - val_loss: 0.1171 - val_accuracy: 0.9527\n",
            "Epoch 3/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0917 - accuracy: 0.9702 - val_loss: 0.0504 - val_accuracy: 0.9824\n",
            "Epoch 4/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9859 - val_loss: 0.0270 - val_accuracy: 0.9927\n",
            "Epoch 5/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9922 - val_loss: 0.0128 - val_accuracy: 0.9961\n",
            "Epoch 6/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.0083 - val_accuracy: 0.9985\n",
            "Epoch 7/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.0052 - val_accuracy: 0.9991\n",
            "Epoch 8/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
            "Epoch 9/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
            "Epoch 10/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0021 - val_accuracy: 0.9994\n",
            "Epoch 11/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0016 - val_accuracy: 0.9997\n",
            "Epoch 12/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
            "Epoch 13/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0010 - val_accuracy: 0.9994\n",
            "Epoch 14/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 8.9124e-04 - val_accuracy: 0.9994\n",
            "Epoch 15/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.2471e-04 - val_accuracy: 0.9997\n",
            "Epoch 16/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 8.9183e-04 - accuracy: 1.0000 - val_loss: 5.2727e-04 - val_accuracy: 0.9997\n",
            "Epoch 17/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 7.2349e-04 - accuracy: 1.0000 - val_loss: 4.8870e-04 - val_accuracy: 0.9997\n",
            "Epoch 18/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.7557e-04 - accuracy: 1.0000 - val_loss: 4.3389e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 3.9137e-04 - accuracy: 1.0000 - val_loss: 4.2837e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 2.6048e-04 - accuracy: 1.0000 - val_loss: 3.7406e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.9020e-04 - accuracy: 1.0000 - val_loss: 4.2115e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.4566e-04 - accuracy: 1.0000 - val_loss: 4.1475e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.0756e-04 - accuracy: 1.0000 - val_loss: 4.3360e-04 - val_accuracy: 1.0000\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 5.7091e-04 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "140/140 [==============================] - 2s 4ms/step - loss: 0.4850 - accuracy: 0.8052 - val_loss: 0.1793 - val_accuracy: 0.9327\n",
            "Epoch 2/100\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.1123 - accuracy: 0.9696 - val_loss: 0.0536 - val_accuracy: 0.9894\n",
            "Epoch 3/100\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.0344 - accuracy: 0.9913 - val_loss: 0.0222 - val_accuracy: 0.9973\n",
            "Epoch 4/100\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.0099 - val_accuracy: 0.9982\n",
            "Epoch 5/100\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.0046 - val_accuracy: 0.9985\n",
            "Epoch 6/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.0026 - val_accuracy: 0.9988\n",
            "Epoch 7/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0017 - val_accuracy: 0.9994\n",
            "Epoch 8/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9994\n",
            "Epoch 9/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 9.4821e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 0.9994\n",
            "Epoch 10/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 6.3858e-04 - accuracy: 1.0000 - val_loss: 8.6595e-04 - val_accuracy: 0.9997\n",
            "Epoch 11/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.1083e-04 - accuracy: 1.0000 - val_loss: 6.5867e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 2.2862e-04 - accuracy: 1.0000 - val_loss: 5.1686e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.2872e-04 - accuracy: 1.0000 - val_loss: 4.2513e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 8.6678e-05 - accuracy: 1.0000 - val_loss: 3.8074e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.8553e-05 - accuracy: 1.0000 - val_loss: 3.5498e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.9352e-05 - accuracy: 1.0000 - val_loss: 3.3182e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 3.9037e-05 - accuracy: 1.0000 - val_loss: 3.0799e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 2.9381e-05 - accuracy: 1.0000 - val_loss: 2.8814e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 2.2232e-05 - accuracy: 1.0000 - val_loss: 2.7873e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.3225e-05 - accuracy: 1.0000 - val_loss: 2.5511e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.3135e-06 - accuracy: 1.0000 - val_loss: 2.4450e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.4450e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.4450e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.4450e-04 - val_accuracy: 1.0000\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 1.5642e-04 - accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "140/140 [==============================] - 2s 4ms/step - loss: 3.2336 - accuracy: 0.6160 - val_loss: 2.4684 - val_accuracy: 0.6945\n",
            "Epoch 2/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 2.2885 - accuracy: 0.7125 - val_loss: 2.0365 - val_accuracy: 0.7382\n",
            "Epoch 3/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.9369 - accuracy: 0.7537 - val_loss: 1.7230 - val_accuracy: 0.7679\n",
            "Epoch 4/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.7115 - accuracy: 0.7779 - val_loss: 1.5857 - val_accuracy: 0.7955\n",
            "Epoch 5/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.5750 - accuracy: 0.7953 - val_loss: 1.4314 - val_accuracy: 0.8121\n",
            "Epoch 6/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.3122 - accuracy: 0.8173 - val_loss: 1.1839 - val_accuracy: 0.8321\n",
            "Epoch 7/100\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 1.0450 - accuracy: 0.8395 - val_loss: 0.9683 - val_accuracy: 0.8533\n",
            "Epoch 8/100\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.8183 - accuracy: 0.8607 - val_loss: 0.7709 - val_accuracy: 0.8664\n",
            "Epoch 9/100\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.7228 - accuracy: 0.8697 - val_loss: 0.7365 - val_accuracy: 0.8742\n",
            "Epoch 10/100\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.6018 - accuracy: 0.8773 - val_loss: 0.5728 - val_accuracy: 0.8706\n",
            "Epoch 11/100\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5376 - accuracy: 0.8818 - val_loss: 0.5360 - val_accuracy: 0.8758\n",
            "Epoch 12/100\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4812 - accuracy: 0.8869 - val_loss: 0.5169 - val_accuracy: 0.8821\n",
            "Epoch 13/100\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4655 - accuracy: 0.8905 - val_loss: 0.5046 - val_accuracy: 0.8852\n",
            "Epoch 14/100\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4564 - accuracy: 0.8957 - val_loss: 0.4946 - val_accuracy: 0.8897\n",
            "Epoch 15/100\n",
            "140/140 [==============================] - 1s 8ms/step - loss: 0.4477 - accuracy: 0.8983 - val_loss: 0.4857 - val_accuracy: 0.8955\n",
            "Epoch 16/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.9008 - val_loss: 0.4797 - val_accuracy: 0.9000\n",
            "Epoch 17/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.9044 - val_loss: 0.4730 - val_accuracy: 0.9027\n",
            "Epoch 18/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.9093 - val_loss: 0.4559 - val_accuracy: 0.9079\n",
            "Epoch 19/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.9138 - val_loss: 0.4160 - val_accuracy: 0.9115\n",
            "Epoch 20/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.9194 - val_loss: 0.4093 - val_accuracy: 0.9164\n",
            "Epoch 21/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.9239 - val_loss: 0.3913 - val_accuracy: 0.9203\n",
            "Epoch 22/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.9266 - val_loss: 0.3603 - val_accuracy: 0.9245\n",
            "Epoch 23/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.9299 - val_loss: 0.3466 - val_accuracy: 0.9276\n",
            "Epoch 24/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.9351 - val_loss: 0.3274 - val_accuracy: 0.9330\n",
            "Epoch 25/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.3062 - accuracy: 0.9380 - val_loss: 0.3034 - val_accuracy: 0.9352\n",
            "Epoch 26/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.9433 - val_loss: 0.2873 - val_accuracy: 0.9406\n",
            "Epoch 27/100\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 0.2597 - accuracy: 0.9478 - val_loss: 0.2660 - val_accuracy: 0.9455\n",
            "Epoch 28/100\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2397 - accuracy: 0.9534 - val_loss: 0.2483 - val_accuracy: 0.9515\n",
            "Epoch 29/100\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2113 - accuracy: 0.9588 - val_loss: 0.2296 - val_accuracy: 0.9567\n",
            "Epoch 30/100\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.1973 - accuracy: 0.9619 - val_loss: 0.2095 - val_accuracy: 0.9600\n",
            "Epoch 31/100\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.1824 - accuracy: 0.9642 - val_loss: 0.1998 - val_accuracy: 0.9636\n",
            "Epoch 32/100\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.1760 - accuracy: 0.9680 - val_loss: 0.1879 - val_accuracy: 0.9658\n",
            "Epoch 33/100\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.1656 - accuracy: 0.9720 - val_loss: 0.1790 - val_accuracy: 0.9688\n",
            "Epoch 34/100\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 0.1575 - accuracy: 0.9747 - val_loss: 0.1675 - val_accuracy: 0.9715\n",
            "Epoch 35/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9774 - val_loss: 0.1466 - val_accuracy: 0.9742\n",
            "Epoch 36/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.1282 - accuracy: 0.9807 - val_loss: 0.1322 - val_accuracy: 0.9785\n",
            "Epoch 37/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.1171 - accuracy: 0.9843 - val_loss: 0.1193 - val_accuracy: 0.9809\n",
            "Epoch 38/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9863 - val_loss: 0.0976 - val_accuracy: 0.9839\n",
            "Epoch 39/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9884 - val_loss: 0.0869 - val_accuracy: 0.9879\n",
            "Epoch 40/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9913 - val_loss: 0.0611 - val_accuracy: 0.9900\n",
            "Epoch 41/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9915 - val_loss: 0.0499 - val_accuracy: 0.9912\n",
            "Epoch 42/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0419 - accuracy: 0.9931 - val_loss: 0.0324 - val_accuracy: 0.9930\n",
            "Epoch 43/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9953 - val_loss: 0.0266 - val_accuracy: 0.9942\n",
            "Epoch 44/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 0.9964 - val_loss: 0.0220 - val_accuracy: 0.9955\n",
            "Epoch 45/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9975 - val_loss: 0.0185 - val_accuracy: 0.9958\n",
            "Epoch 46/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9978 - val_loss: 0.0150 - val_accuracy: 0.9967\n",
            "Epoch 47/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9984 - val_loss: 0.0096 - val_accuracy: 0.9976\n",
            "Epoch 48/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9991 - val_loss: 0.0070 - val_accuracy: 0.9982\n",
            "Epoch 49/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9991 - val_loss: 0.0054 - val_accuracy: 0.9985\n",
            "Epoch 50/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0032 - val_accuracy: 0.9997\n",
            "Epoch 51/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0025 - val_accuracy: 0.9997\n",
            "Epoch 52/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0019 - val_accuracy: 0.9997\n",
            "Epoch 53/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 9.4320e-04 - accuracy: 0.9996 - val_loss: 9.1465e-04 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 7.8943e-04 - accuracy: 0.9996 - val_loss: 7.3511e-04 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 6.7463e-04 - accuracy: 0.9998 - val_loss: 6.0984e-04 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 5.7095e-04 - accuracy: 1.0000 - val_loss: 4.5827e-04 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.8209e-04 - accuracy: 1.0000 - val_loss: 3.8178e-04 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 4.1680e-04 - accuracy: 1.0000 - val_loss: 3.2580e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 3.6721e-04 - accuracy: 1.0000 - val_loss: 2.6949e-04 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 3.1827e-04 - accuracy: 1.0000 - val_loss: 2.3528e-04 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 2.7902e-04 - accuracy: 1.0000 - val_loss: 1.9852e-04 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 2.4031e-04 - accuracy: 1.0000 - val_loss: 1.6529e-04 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 2.0231e-04 - accuracy: 1.0000 - val_loss: 1.3544e-04 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.7329e-04 - accuracy: 1.0000 - val_loss: 1.0678e-04 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.4769e-04 - accuracy: 1.0000 - val_loss: 8.4154e-05 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.3086e-04 - accuracy: 1.0000 - val_loss: 7.7740e-05 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 1.1432e-04 - accuracy: 1.0000 - val_loss: 7.1077e-05 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 9.6613e-05 - accuracy: 1.0000 - val_loss: 6.6533e-05 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 8.0039e-05 - accuracy: 1.0000 - val_loss: 6.3432e-05 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "140/140 [==============================] - 0s 3ms/step - loss: 6.6337e-05 - accuracy: 1.0000 - val_loss: 6.1288e-05 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            " 82/140 [================>.............] - ETA: 0s - loss: 1.2946e-05 - accuracy: 1.0000"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_search_cv.best_params_"
      ],
      "metadata": {
        "id": "aheP6CG5Lmb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_search_cv.best_score_\n"
      ],
      "metadata": {
        "id": "X5swlSG0L4ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_UZAZ1g9L7JJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}